# This is the main configuration file for the application.

# configuration can be specified using dot notation or object notation.
# For example this:
# clowder.diskStorage.path="/tmp/clowder"
# clowder.diskStorage.depth=3
# and this is the same.
# clowder {
#   disktStorage {
#     path="/tmp"/clowder"
#     depth=3
#   }
# }
#
# this is import since it could lead to unexpected results:
# foo=5
# foo.bar=7
# now foo is an object and no longer has value 5, but has a property bar which is 7.

# ~~~~~

# Host machine IP to connect from outside, also set the SWAGGER
# URL.
hostIp = "localhost"

# how large a buffer should be used to stream data to user from
# clowder. Scala default is 8KB, clowder default is 1MB.
clowder.chunksize = 1048576

# body parser maximum content length
# based on Max BSON size 16777216, otherwise it gives exception
parsers.text.maxLength=20M

# cross site
cors.allowed.domain="*"

# Disable plugins we don't need
dbplugin = disabled
evolutionplugin = disabled
ehcacheplugin = disabled

# path to put application, if not specified this will be hosted as
# the root application. If this is fronted by nginx or apache and
# using proxy set this to the same path as the webserver path.
#application.context="/clowder"

# Intermediate extractor results cleanup time params (in hours)
intermediateCleanup.checkEvery=1
intermediateCleanup.removeAfter=24

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Permissions
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# What setup should clowder use for permissions this can be either:
# - private : everything needs a valid login
# - public  : anonymous can do all read operations
# The default is public, if you set this to private your probably
# want to set registerThroughAdmins=true and set the admin for the
# server.
permissions = public

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Signup
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Initial admins of app, this is a list of email addresses who will
# get an email when a new user signs up. This can also be configured
# in the admin menu
initialAdmins=""

# Whether emails for new users registrations go through admins first
registerThroughAdmins=true

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Secret key
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use
# the same key!
application.secret="tZ8tQPGe3_QI6ZtSDNs;/4O:F:cIk15fy2R^5HiT;TY?31K59WuwYvAa;I8b/0J9"

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Secret Extractor key
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# this should be changed. This key is send to the extractors to
# access the data.
# TODO this is an admin key and should not exist.
commKey=r1ek3rs

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# License information
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# licenseType, currently:
# - license1 : corresponds to Limited
# - license2 : corresponds to Creative Commons
# - license3 : corresponds to Public Domain
#
# licenseText, currently tied to the licenseType
# - license1 : Free text that a user can enter to describe the license
# - license2 : 1 of 6 options (or their abbreviations) that reflects the specific set of
#              options associated with the Creative Commons license, these are:
#              1) Attribution-NonCommercial-NoDerivs (by-nc-nd)
#              2) Attribution-NoDerivs (by-nd)
#              3) Attribution-NonCommercial (by-nc)
#              4) Attribution-NonCommercial-ShareAlike (by-nc-sa)
#              5) Attribution-ShareAlike (by-sa)
#              6) Attribution (by)
# - license3 : Public Domain Dedication
#
# rightsHolder, currently only required if licenseType is license1. Reflects the specific
#               name of the organization or person that holds the rights
# licenseUrl, free text that a user can enter to go with the licenseText in the case of
#             license1. Fixed URL's for the other 2 cases.
#
# allowDownload, true or false, whether the file or dataset can be downloaded. Only relevant for license1 type.
clowder.license {
  type="license1"
  url=""
  text="All Rights Reserved"
  holder=""
  commercial=false
  derivative=false
  share=false
  download=false
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Space related information
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# isTimeToLiveEnabled, whether or not spaces should be checking if resources are expired.
#  - true : Resources (datasets and collections) assigned to a space will be subject to purging when expired
#  - false : No purging of resources will happen. This is the default setting.
#
# timeToLive, the default time that spaces should keep resources before purging them, in hours. Default value is 720 (30 days).
#
clowder.space {
    isTimeToLiveEnabled=false
    timeToLive=720
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Required Fields related information
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# isNameRequired, whether or not resources checking this should require a name.
#  - true : Resources (datasets, collections, and spaces) must have a name. This is the default setting.
#  - false : No name is required
#
# isDescriptionRequired, whether or not resources checking this should require a description.
#  - true : Resources (datasets, collections, and spaces) must have a description.
#  - false : No description is required. This is the default setting.
clowder.requiredfields {
    isNameRequired=true
    isDescriptionRequired=false
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# The application languages
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# currently there is no internationalization in clowder and all text
# is in english.
application.langs="en"

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Swagger configuration
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# version number associated with the API
api.version="beta"
# not sure why this does not work
#swagger.api.info {
#  contact="Luigi Marini <lmarini@illinois.edu>"
#  description="",
#  title="Clowder REST API documentation",
#  termsOfService=""
#  license="NCSA Open Source License"
#  licenseUrl="http://opensource.org/licenses/UoI-NCSA"
#}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# MongoDB
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# The default is for code to use mongo to store all information. This
# will specify how to connect to the mongodb server.
# see http://www.mongodb.org/display/DOCS/Connections
# mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]
mongodbURI = "mongodb://127.0.0.1:27017/clowder"


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# RabbitMQ
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# All requests to extractors and any other external process is send
# using rabbitmq, this will setup the connection information.
clowder.rabbitmq.uri="amqp://guest:guest@localhost:5672/%2f"
#clowder.rabbitmq.managmentPort=15672
#clowder.rabbitmq.exchange=clowder
# Following variable will use the url when sending messages over rabbitmq. This can be used in a docker
# environment to force the use of a specific hostname when contacting clowder from the extractors. If
# this is not specified the public URL of clowder will be used.
#clowder.rabbitmq.clowderurl=NONE

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Settings for the PostgreSQL
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Configuration for the postgresql plugin. This will store any of the
# geostreaming API calls. Currently this is the only available
# plugin to store geostreaming data.
# TODO: change this to a JDBC URL
#postgres.user=clowder
#postgres.password=postgresPassword

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# GeoStreaming
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# should some of the data be cached for geostream calls. Set this to
# the folder where geostream information can be stored. This will
# create 2 files, one with extension json and one without an
# extension. The json extension file will give information about what
# is stored in the cache. Always remove both files if space becomes
# an issue.
#geostream.cache=/tmp/clowder
#geostream.dashboard.url=""

# The following properties are used when the geostreaming service
# returns the data as type csv instead of json.
json2csv.ignore="type,geometry|type"
json2csv.hideprefix=true
json2csv.seperator=|
json2csv.fixgeometry=true

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# MongoDBFileService PLUGINS
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# the default is to use MongoDBFileService and does not require any
# other configuration settings.
service.files=services.mongodb.MongoDBFileService


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# S3 Plugin
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# Point at AWS S3, or start MinIO up a MinIO container:
#    $ docker run --name=minio -itd -p 8000:9000 -v $(pwd)/example-bucket:/data minio/minio server /data --compat
#
# To view the logs / retrieve credentials:
#    $ docker logs -f minio
#
# You should see something similar to the following in the logs:
#      Endpoint:  http://172.17.0.6:9000  http://127.0.0.1:9000
#      AccessKey: W0ZTICFRNY2IPDK96QAA
#      SecretKey: sgSXcoO3t94EiN3K2bjBM8MaKAo2EnL7sGCJdcsr
#
# Point the ServiceEndpoint at your bucket's S3 service provider and
# copy the AccessKey / SecretKey into your configuration, as below.
#
# To use the S3 service, uncomment the following line and specify the
# location of the bucket where files should be written along with the
# credentials that should be used to access it.
#
#service.byteStorage=services.s3.S3ByteStorageService
#
# Default configuration for the example MinIO setup above:
# NOTE: Clowder and MinIO both use port 9000, so we map MinIO to port 8000.
clowder.s3.serviceEndpoint="http://localhost:8000"
clowder.s3.bucketName="clowder-uploads"
clowder.s3.accessKey="W0ZTICFRNY2IPDK96QAA"
clowder.s3.secretKey="sgSXcoO3t94EiN3K2bjBM8MaKAo2EnL7sGCJdcsr"
clowder.s3.region="us-east-1"
clowder.s3.depth=3

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Log Plugin
# leave those variables empty will turn off the log from GUI, namely,
# `View Logs` on the extractors explore page will not be visible.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# log service endpoint.e.g., http://localhost:9000
clowder.log.serviceEndpoint=""
# login username
clowder.log.username=""
# login password
clowder.log.password=""
# extractor service name prefix, e.g., clowder-dev_
clowder.log.extractorNamePrefix=""

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# FileSystemDB Plugin
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# To use the filesystem uncomment the following line and specify the
# location on disk where files should be written if using the
# FileSystemDB storage option as well as the number of subfolders.
#service.byteStorage=services.filesystem.DiskByteStorageService

# configuration for disk byte storage
clowder {
  diskStorage {
    path="/home/clowder/data"
    depth=3
  }
}

# Whitelist of locations that are valid sources for uploading by file path.
# Files in these folders can be added to Clowder/Mongo by posting a path to
# them, rather than posting the file itself. Other locations will be rejected.
filesystem.sourcepaths=[
  "/home/globus",
]

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# IRODSPlugin Plugin
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# To use the IRODS filesystem uncomment the following line
#service.byteStorage=services.irods.IRODSByteStorageService
#
# iRODS server host name
irods.host=localhost
# iRODS server port number
irods.port=1247
# Account name
irods.username=anonymous
# Account password
## if irods.username=anonymous use "" for password (irods.password="")
irods.password=""
# Default storage resource name
irods.defaultStorageResource= demoResc
# iRODS zone
irods.zone=tempZone
# Home directory in iRODS
irods.userhome=/tempZone/home/public
# Current directory in iRODS
irods.usercurrent=/tempZone/home/public

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Elasticsearch
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
elasticsearchSettings.clusterName=""
elasticsearchSettings.serverAddress="localhost"
elasticsearchSettings.serverPort=9300
elasticsearchSettings.indexNamePrefix="clowder"
elasticsearchSettings.maxResults=240

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# ToolManager Plugin
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
toolmanagerURI="http://192.168.99.100:8080"

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Versus
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
versus.host="http://localhost:8080/api/v1"

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# DTS
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#temporary directory for upload file based on url
tmpdir=/var/tmp/dtsdir/

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# DTS Extension Host URL
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dts.extension.host = "http://browndog.ncsa.illinois.edu"

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Google API Keys
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
google.maps.key = "AIzaSyBJHzizWxzgqkH9Ipr_cGSjCWpeuY8M4ac"

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Data dumps
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#Dumps variables
#For both files and datasets, there MUST be a directory to copy the files initially to. Optionally, another directory to move them to
#(by renaming) after they are copied
filedump.dir="C:\\mongodumpfiles"
#filedump.dir="/var/tmp/clowder/mongodumpfiles"
filedumpmove.dir="C:\\mongodumpfilesmove"
#filedumpmove.dir="/var/tmp/clowder/mongodumpfilesmove"

datasetdump.dir="C:\\mongodumpdatasets"
#datasetdump.dir="/var/tmp/clowder/mongodumpdatasets"
datasetdumpmove.dir="C:\\mongodumpdatasetsmove"
#datasetdumpmove.dir="/var/tmp/clowder/mongodumpdatasetsmove"

#default uri for metadata definition when uri is not set
metadata.uri.prefix="http://clowder.ncsa.illinois.edu/metadata"

#Dump every how many days (if the associated autodumper plugin is activated)
filemetadatadump.dumpEvery=1
datasetmetadatadump.dumpEvery=1
datasetdump.dumpEvery=1

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# RDF
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#RDF metadata export variables
#Dircount is the number of mappings to use. Each schema path follows, defined as filesxmltordfmapping.dir_<schema number> or datasetsxmltordfmapping.dir_<schema number>
#First schema is also used for generating RDF metadata to upload to a communicating RDF store, if such is used
filesxmltordfmapping.dircount = "1"
filesxmltordfmapping.dir_1="conf\\fileUserMetadataRDFMapping.xml"

datasetsxmltordfmapping.dircount = "1"
datasetsxmltordfmapping.dir_1="conf\\datasetUserMetadataRDFMapping.xml"

#rdfdumptemporary.dir="C:\\rdfdumptemporaryfiles"
rdfdumptemporary.dir="/var/tmp/clowder/rdfdumptemporaryfiles"

#Community-generated metadata temp exports cleanup time params (in minutes)
rdfTempCleanup.checkEvery=30
rdfTempCleanup.removeAfter=5

#RDF store and SPARQL stuff

userdfSPARQLStore="no"
rdfEndpoint="http://clowder-dev.cyi.ac.cy:10100"
rdfXMLGraphName="http://clowder-dev.cyi.ac.cy/xmlRDF"
rdfCommunityGraphName="http://clowder-dev.cyi.ac.cy/usersRDF"
rootNodesFile="conf\\rdfRootNodes.txt"
datasetRootNodesFile="conf\\datasetRdfRootNodes.txt"

#RDF store update interval (in hours)
#rdfRepoUpdate.updateEvery=24

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Profile
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Default image for user with no gravatar
# View list of options at https://en.gravatar.com/site/implement/images/
default_gravatar="mm"

# Number of recommendations to display after following an entity
number_of_recommendations=10

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Videos navigation
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
navOnSectionClick=true

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Space Advanced Configuration
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
enable_expiration=false

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Show previews when uploading, default is enabled. When uploading
# many images this will result in many previews being created and
# could slow down the upload.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#clowder.upload.previews=true

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Maximum tag length
# Setting this larger than 1000 will result in problems with the
# index generated on tags.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
clowder.tagLength=100

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Whether or not datasets are automatically added to the
# spaces of a collection when a dataset is created within a collection,
# or when a dataset is added to a collection or a collection
# is added to a space
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
addDatasetToCollectionSpace=false

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Whether or not collections or datasets download in bagit format
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
downloadCollectionBagit = true
downloadDatasetBagIt = false

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Polyglot
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#url to get all outputs for given input
polyglot.inputsURL="http://dap-dev.ncsa.illinois.edu:8184/inputs/"
#url to convert a file
polyglot.convertURL="http://dap-dev.ncsa.illinois.edu:8184/convert/"
#for connecting to polyglog server
polyglot.username = "browndog.user"
# DO NOT check in the password. The user needs to enter the correct pwd here.
polyglot.password = ""

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Staging Area
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
stagingarea.uri =      "https://seadva-test.d2i.indiana.edu/sead-c3pr/api/researchobjects"

matchmaker.uri =       "https://seadva-test.d2i.indiana.edu/sead-c3pr/api/researchobjects/matchingrepositories"
people.uri =           "https://seadva-test.d2i.indiana.edu/sead-c3pr/api/people"

publishData.list.uri = "https://seadva-test.d2i.indiana.edu/sead-c3pr/api/search"


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Verified and Public Spaces
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Enable the user to set if spaces/collections/datasets should
# be public or private. This allows the user to toggle things with
# regard to the permission that is set above.
enablePublic = false

# Are new spaces required to be verified by a serveradmin before it
# will show up in the spaces list.
verifySpaces = false

# allowed combinations of Verified and Public Spaces conf
# permissions = private, enablePublic = true, verifySpaces = true (SEAD)
# permissions = private, enablePublic = true, verifySpaces = false
# permissions = private, enablePublic = false, verifySpaces = false
# permissions = public, enablePublic = false, verifySpaces = false(Rob's case & default conf)

# Move file between datasets within the space,
# false - default - move to all datsets a user has access to
# true - datasets restricted only to the space
datasetFileWithinSpace = false

# allow public users to download files.
allowAnonymousDownload = false

#When a comment is left on an object, the owner of the object as well as the people who belong
# to the space and have permission to view comments get an event about the comment in their event feed.
# please use default setting when loading the homepage is too slow.
showCommentOnHomepage = false

# if this is true, then datasets, collections, spaces a user has created but which are not shared
# will not be visible
showOnlySharedInExplore = false

# if this is true, then all users and anonymous will have Permission.ViewGeoStream = true
makeGeostreamsPublicReadable = true

# if this is true, then delete will send a collection or dataset to trash instead of just deleted
useTrash = false

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Help Menu
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
helpMenu = []

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Sortable space and dataset lists: this will load all items in 
# memory, so it is bad for databases with large numbers of Datasets 
# or Collections in Spaces, or with large numbers of Files in a 
# Folder. See also SEAD-1055
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
sortInMemory = false

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Different AKKA contexts to be used
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
akka {
  actor {
    contexts {
      file-processing {
        fork-join-executor {
          parallelism-max = 10
        }
      }
    }
  }
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Internationalization
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
play.i18n.langs = [ "en-US" ]

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Disable events view. On systems with many events this can cause
# a problem. This allows you to disable events. This is a known issue
# and will be fixed in the next release at which point this flag will
# no longer be used
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
clowder.disable.events = false

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# show the username/password login. If this is set to false, or the
# plugin is disabled it will not show the username/password prompt
# when logging in.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
enableUsernamePassword = true

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Archival
#
# Allows admins to archive file bytes by submitting the file to
# a special "archival" extractor. Such extractors take a parameter
# "operation" with two possible values: "archive" or "unarchive".
# "archive" and "unarchive" should be purely inverse operations, such
# that unarchive(archive(x)) == x for any valid input.
#
# See https://github.com/clowder-framework/extractors-archival for available extractors
#
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
archiveEnabled=false
archiveAllowUnarchive=false
#archiveExtractorId="ncsa.archival.s3"
archiveExtractorId="ncsa.archival.disk"

# NOTE: Setting interval to zero will disable automatic archiving
archiveAutoInterval=0                 # in seconds (e.g. 86400 == 24 hours)
archiveAutoDelay=120                  # in seconds (e.g. 86400 == 24 hours)
archiveAutoAfterInactiveCount=90      # NOTE: Setting count to zero will disable automatic archiving
archiveAutoAfterInactiveUnits="days"
archiveAutoAboveMinimumStorageSize=1000000

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Configuration file for securesocial
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
include "securesocial.conf"

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Content types
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# mapping of file extension to mime-type
include "mimetypes.conf"

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Customization
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
include "custom.conf"
